{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is originally obtained from https://github.com/paul-rottger/hatecheck-experiments and modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#import preprocessor\n",
    "from html import unescape\n",
    "import re\n",
    "import string\n",
    "import wordsegment as ws\n",
    "#import emoji\n",
    "ws.load() # load vocab for word segmentation\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0553e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_match_segmentation(match):\n",
    "    return ' '.join(ws.segment(match.group(0)))\n",
    "# Define function for cleaning text\n",
    "def clean_text(text):\n",
    "    \n",
    "    # convert HTML codes\n",
    "    text = unescape(text)\n",
    "    \n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # replace mentions, URLs and emojis with special token\n",
    "    text = re.sub(r\"@[A-Za-z0-9_-]+\",'[USER]',text)\n",
    "    text = re.sub(r\"u/[A-Za-z0-9_-]+\",'[USER]',text)\n",
    "    text = re.sub(r\"http\\S+\",'[URL]',text)\n",
    "    \n",
    "    # find and split hashtags into words\n",
    "    text = re.sub(r\"#[A-Za-z0-9]+\", regex_match_segmentation, text)\n",
    "\n",
    "    # remove punctuation at beginning of string (quirk in Davidson data)\n",
    "    text = text.lstrip(\"!\")\n",
    "    text = text.lstrip(\":\")\n",
    "    \n",
    "    # remove newline and tab characters\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = text.replace('\\t',' ')\n",
    "    text = text.replace('[linebreak]', ' ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec431a",
   "metadata": {},
   "source": [
    "## CAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433aa707",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_train = pd.read_csv(\"../cad_naacl2021/data/cad_v1_1_train.tsv\", sep=\"\\t\")\n",
    "cad_valid = pd.read_csv(\"../cad_naacl2021/data/cad_v1_1_dev.tsv\", sep=\"\\t\")\n",
    "cad_test = pd.read_csv(\"../cad_naacl2021/data/cad_v1_1_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "dfs = [cad_train, cad_valid, cad_test]\n",
    "\n",
    "for dd in dfs: \n",
    "    dd.text = dd.text.astype(str).apply(lambda tt: clean_text(tt))\n",
    "    dd.labels = dd.labels.apply(lambda x: x.split(','))\n",
    "    \n",
    "cad_train_hateful = cad_train.copy()\n",
    "cad_valid_hateful = cad_valid.copy()\n",
    "cad_test_hateful = cad_test.copy()\n",
    "\n",
    "cad_train_abusive = cad_train.copy()\n",
    "cad_valid_abusive = cad_valid.copy()\n",
    "cad_test_abusive = cad_test.copy()\n",
    "\n",
    "hate_dfs = [cad_train_hateful, cad_valid_hateful, cad_test_hateful]\n",
    "abuse_dfs = [cad_train_abusive, cad_valid_abusive, cad_test_abusive]\n",
    "\n",
    "for dd, oo in zip(hate_dfs, dfs):\n",
    "    dd['label'] = oo.labels.apply(lambda x: 1 if 'IdentityDirectedAbuse' in x else 0)\n",
    "    dd = dd.drop(columns=['labels'])\n",
    "    \n",
    "for dd, oo in zip(abuse_dfs, dfs):\n",
    "    dd['label'] = oo.labels.apply(lambda x: 0 if ('Neutral' in x) or ('CounterSpeech' in x) else 1)\n",
    "    dd = dd.drop(columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168aa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_train_abusive.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_train_hateful.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c517c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_train_abusive.to_csv('Data/CAD_abuse/train.csv')\n",
    "cad_valid_abusive.to_csv('Data/CAD_abuse/valid.csv')\n",
    "cad_test_abusive.to_csv('Data/CAD_abuse/test.csv')\n",
    "\n",
    "cad_train_hateful.to_csv('Data/CAD_hate/train.csv')\n",
    "cad_valid_hateful.to_csv('Data/CAD_hate/valid.csv')\n",
    "cad_test_hateful.to_csv('Data/CAD_hate/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f455b86f",
   "metadata": {},
   "source": [
    "## Founta\n",
    "\n",
    "For this dataset, we've already created a train-valid-test split while prepping the data for ILM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "founta_train = pd.read_csv(\"Data/Founta/train.csv\", index_col=0)\n",
    "founta_valid = pd.read_csv(\"Data/Founta/valid.csv\",index_col=0)\n",
    "founta_test = pd.read_csv(\"Data/Founta/test.csv\", index_col=0)\n",
    "\n",
    "dfs = [founta_train, founta_valid, founta_test]\n",
    "\n",
    "for dd in dfs:\n",
    "    dd.drop(dd[dd.label == 'spam'].index, inplace=True)\n",
    "    dd.text = dd.text.astype(str).apply(lambda tt: clean_text(tt))\n",
    "    dd = dd.drop(columns=['count_label_votes'])\n",
    "\n",
    "founta_train_abusive = founta_train.copy()\n",
    "founta_valid_abusive = founta_valid.copy()\n",
    "founta_test_abusive = founta_test.copy()\n",
    "\n",
    "founta_train_hateful = founta_train.copy()\n",
    "founta_valid_hateful = founta_valid.copy()\n",
    "founta_test_hateful = founta_test.copy()\n",
    "\n",
    "abuse_dfs = [founta_train_abusive, founta_valid_abusive, founta_test_abusive]\n",
    "hate_dfs = [founta_train_hateful, founta_valid_hateful, founta_test_hateful]\n",
    "\n",
    "for dd in abuse_dfs:\n",
    "    dd.label.replace({'hateful': 1, \"abusive\": 1, \"normal\": 0}, inplace = True)\n",
    "\n",
    "for dd in hate_dfs:\n",
    "    dd.label.replace({'hateful': 1, \"abusive\": 0, \"normal\": 0}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f55757",
   "metadata": {},
   "outputs": [],
   "source": [
    "founta_train_abusive.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdef293",
   "metadata": {},
   "outputs": [],
   "source": [
    "founta_train_hateful.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34578d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "founta_train_abusive.to_csv('Data/Founta_abuse/train.csv')\n",
    "founta_valid_abusive.to_csv('Data/Founta_abuse/valid.csv')\n",
    "founta_test_abusive.to_csv('Data/Founta_abuse/test.csv')\n",
    "\n",
    "founta_train_hateful.to_csv('Data/Founta_hate/train.csv')\n",
    "founta_valid_hateful.to_csv('Data/Founta_hate/valid.csv')\n",
    "founta_test_hateful.to_csv('Data/Founta_hate/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a52118",
   "metadata": {},
   "source": [
    "## Davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "davidson2017 = pd.read_csv('./Data/davidson2017.csv', index_col=0)\n",
    "davidson2017.rename(columns={\"class\": \"label\", \"tweet\": \"text\"}, inplace=True, errors='ignore')\n",
    "davidson2017 = davidson2017[['text','label']]\n",
    "davidson2017.text = davidson2017.text.astype(str).apply(lambda tt: clean_text(tt))\n",
    "davidson2017.label.replace({0: \"hateful\", 1: \"offensive\", 2: \"neither\"}, inplace = True)\n",
    "\n",
    "davidson_train, davidson_valtest = train_test_split(davidson2017, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=davidson2017.label, \n",
    "                                                    random_state=123)\n",
    "davidson_valid, davidson_test = train_test_split(davidson_valtest, \n",
    "                                                 test_size=0.5, \n",
    "                                                 stratify=davidson_valtest.label, \n",
    "                                                 random_state=123)\n",
    "\n",
    "d_train_offense = davidson_train.copy()\n",
    "d_valid_offense = davidson_valid.copy()\n",
    "d_test_offense = davidson_test.copy()\n",
    "\n",
    "d_train_hate = davidson_train.copy()\n",
    "d_valid_hate = davidson_valid.copy()\n",
    "d_test_hate = davidson_test.copy()\n",
    "\n",
    "dfs_offense = [d_train_offense, d_valid_offense, d_test_offense]\n",
    "dfs_hate = [d_train_hate, d_valid_hate, d_test_hate]\n",
    "\n",
    "for dd in dfs_offense:\n",
    "    dd.label.replace({'hateful': 1, 'offensive': 1, 'neither': 0}, inplace = True)\n",
    "    \n",
    "for dd in dfs_hate: \n",
    "    dd.label.replace({'hateful': 1, 'offensive': 0, 'neither': 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_offense.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_hate.groupby('label').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_offense.to_csv(\"Data/Davidson_abuse/train.csv\")\n",
    "d_valid_offense.to_csv(\"Data/Davidson_abuse/valid.csv\")\n",
    "d_test_offense.to_csv(\"Data/Davidson_abuse/test.csv\")\n",
    "\n",
    "d_train_hate.to_csv(\"Data/Davidson_hate/train.csv\")\n",
    "d_valid_hate.to_csv(\"Data/Davidson_hate/valid.csv\")\n",
    "d_test_hate.to_csv(\"Data/Davidson_hate/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
