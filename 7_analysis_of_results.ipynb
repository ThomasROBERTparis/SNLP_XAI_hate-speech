{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6199fb",
   "metadata": {},
   "source": [
    "This notebook contains the the results for necessity and sufficiency. Necessity and sufficiency are both calculated by either choosing a subset of tokens and perturbing them using the ILM model. The models are all BERT architecture, but trained on different datasets, and for each dataset, a model is trained on both hate/non-hate and abusive/non-abusive labels. The explanations are generated for 120 examples from the HateCheck test suite. These are instances that are explicitly hateful, and are targeted towards women or Muslims. The function ```display_scores``` displays the necessity and sufficiency for each of the examples for all models included. Note that some models will display ```NaN``` for some values. These are the cases where the model mistakenly classified the original instance as non-abusive/non-hateful. In these cases, the current necessity and sufficiency calculations aren't meaningful, because we aim to provide explanations for positive predictions only. The third argument to this function determines which necessity/sufficiency scores to display. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e0c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_bert-base-uncased_lr5e-05\"\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_bert-large-uncased_lr0.0001\"\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_roberta-base_lr5e-05\"\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_distilbert-base-uncased_lr0.0001\"\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_distilroberta-base_lr2e-05\"\n",
    "\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_bert-base-uncased_LoRA_r16_lr0.0001\"\n",
    "# model_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_bert-large-uncased_LoRA_r16_lr0.0001\"\n",
    "# Dmodel_name = \"ThomasROBERTparis/SNLP_XAI_hate-speech_Davidson_hate_roberta-base_LoRA_r16_lr2e-05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd92dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# preds = pickle.load(open(\"Data/HateCheck_necc_suff_preds.pickle\", \"rb\"))\n",
    "# results = pickle.load(open(\"Data/HateCheck_necc_suff_results_all.pickle\", \"rb\"))\n",
    "# perturbations = pickle.load(open(\"Data/intermediate outputs/HateCheck_necc_suff_perturbations.pickle\",\"rb\"))\n",
    "\n",
    "# preds = pickle.load(open(\"Data/Reproduction/HateCheck_necc_suff_preds.pickle\", \"rb\"))\n",
    "# results = pickle.load(open(\"Data/Reproduction/HateCheck_necc_suff_results_all.pickle\", \"rb\"))\n",
    "# perturbations = pickle.load(open(\"Data/Reproduction/HateCheck_necc_suff_perturbations_0_20.pickle\",\"rb\"))\n",
    "\n",
    "preds = pickle.load(open(\"Data/Reproduction_full/\"+model_name+\"/HateCheck_necc_suff_preds.pickle\", \"rb\"))\n",
    "results = pickle.load(open(\"Data/Reproduction_full/\"+model_name+\"/HateCheck_necc_suff_results_all.pickle\", \"rb\"))\n",
    "perturbations = pickle.load(open(\"Data/Reproduction_full/HateCheck_necc_suff_perturbations_not_finetuned.pickle\",\"rb\"))\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f30c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23010cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(results['necc_results'].keys())\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737feff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corrupted examples with tokn k flipped together with the corresponding scores\n",
    "# if this is sufficiency, set reverse=True so that it will return instances where token k is not flipped\n",
    "def get_k_corr(k, masks, perturbed, p_results, reverse=False):\n",
    "    perturbed_k = []\n",
    "    for pp, mm, rr in zip(perturbed, masks[:,k], p_results):\n",
    "        if mm != reverse:\n",
    "            perturbed_k.append((pp, rr))\n",
    "    return(perturbed_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaab936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given original test case, make a table for necessity or sufficiency for each model and for each token\n",
    "\n",
    "def display_scores(templ_n, orig_texts, orig_preds, scores_dict):\n",
    "    columns = orig_texts[templ_n].strip().split()\n",
    "    index = list(scores_dict.keys())\n",
    "    # if the model has not predicted the original as 0, do not display the feature attribution scores\n",
    "    data = np.array([scores_dict[dset][templ_n] if orig_preds[dset][templ_n] == 1 \n",
    "                     else [np.nan]*len(scores_dict[dset][templ_n]) \n",
    "                    for dset in scores_dict.keys()])\n",
    "    return pd.DataFrame(data=data, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"necessity\")\n",
    "for i in range(len(perturbations['orig_texts'])):\n",
    "    print(display_scores(i, perturbations['orig_texts'],  preds['orig_preds'], results['necc_results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sufficiency\")\n",
    "for i in range(len(perturbations['orig_texts'])):\n",
    "    print(display_scores(i, perturbations['orig_texts'],  preds['orig_preds'], results['suff_results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function is to examine the perturbations and the scores a model assigned them. \n",
    "# # Will not work for masked-not-perturbed versions. \n",
    "\n",
    "# ex_no = 0 # example in the examples list\n",
    "# id_token = 2  #the identity token is the _th token\n",
    "# model = 'Davidson_hate'\n",
    "# get_k_corr(id_token, \n",
    "#            perturbations['suff_masks'][ex_no], \n",
    "#            perturbations['suff_perturbed'][ex_no], \n",
    "#            preds['suff_scores'][model][ex_no], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf1a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex_no = 0 # example in the examples list\n",
    "# id_token = 2  #the identity token is the _th token\n",
    "# model = 'CAD_abuse'\n",
    "# get_k_corr(id_token, \n",
    "#            perturbations['necc_masks'][ex_no], \n",
    "#            perturbations['necc_perturbed'][ex_no], \n",
    "#            preds['necc_scores'][model][ex_no])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c3a3c",
   "metadata": {},
   "source": [
    "In the following section, there is the average prediction of the models for the cases where identities are mentioned in neutral or positive contexts (```ident_neutral_nh```, ```ident_pos_nh```) and the test cases where there is \"abuse\" directed to non-protected groups (```target_group_nh```) individuals (```target_indiv_nh```) and objects (```target_obj_nh```). The performance of the models on non-abusive mention identities for the two targets we've chosen for our explanations ('women' and 'Muslims') is also given seperately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016715eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# hc_results = pickle.load(open('Data/intermediate outputs/HateCheck_templates_and_results.pickle', \"rb\"))\n",
    "hc_results = pickle.load(open(\"Data/Reproduction_full/\"+model_name+\"/HateCheck_templates_and_results.pickle\", \"rb\"))\n",
    "###\n",
    "hc_results.test_case = hc_results.test_case.apply(lambda x: x.strip())\n",
    "hc_results.target_ident.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_results_women_nh = hc_results[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'women')]\n",
    "\n",
    "hc_results_men_nh = hc_results[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'men')]\n",
    "\n",
    "hc_results_muslims_nh = hc_results[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'Muslim')]\n",
    "\n",
    "hc_results_catholics_nh = hc_results[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'Catholic')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf8aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_results.functionality.loc[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'women')] = 'women_nh'\n",
    "\n",
    "hc_results.functionality.loc[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'men')] = 'men_nh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_results.functionality.loc[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'Muslims')] = 'muslims_nh'\n",
    "\n",
    "hc_results.functionality.loc[((hc_results.functionality == 'ident_neutral_nh') \n",
    "                         | (hc_results.functionality == 'ident_pos_nh')) \n",
    "                        & (hc_results.target_ident == 'Catholics')] = 'catholics_nh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a08913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results we are interested are: \n",
    "target_funcs = ['women_nh', 'men_nh', 'muslims_nh', 'catholics_nh', 'target_obj_nh', 'target_indiv_nh', 'target_group_nh']\n",
    "\n",
    "target_funcs_results = hc_results[hc_results.functionality.isin(target_funcs)]\n",
    "# get average score per functionality\n",
    "target_funcs_results.groupby('functionality')[['{}_pred'.format(dd) for dd in datasets]].mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_results = pickle.load(open('Data/intermediate outputs/HateCheck_necc_suff_results_masked.pickle', 'rb'))\n",
    "# mask_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "necc_vals = {}\n",
    "suff_vals = {}\n",
    "necc_vals_mask = {}\n",
    "suff_vals_mask = {}\n",
    "orig_texts = []\n",
    "targets = []\n",
    "\n",
    "for tt in perturbations['orig_texts']:\n",
    "    orig_text = tt.strip()\n",
    "    row = hc_results[hc_results.test_case == orig_text]\n",
    "    targets.append(row.target_ident.tolist()[0])\n",
    "\n",
    "for dataset in datasets:\n",
    "    necc_vals[dataset] = []\n",
    "    suff_vals[dataset] = []\n",
    "    necc_vals_mask[dataset] = []\n",
    "    suff_vals_mask[dataset] = []\n",
    "    for nn, (orig_text, orig_pred) in enumerate(zip(perturbations['orig_texts'], preds['orig_preds'][dataset])):\n",
    "        if orig_pred != 1:\n",
    "            necc_vals[dataset].append(np.nan)\n",
    "            suff_vals[dataset].append(np.nan)\n",
    "            necc_vals_mask[dataset].append(np.nan)\n",
    "            suff_vals_mask[dataset].append(np.nan)\n",
    "            continue\n",
    "        # get the row in hc_results corresponding to this case\n",
    "        orig_text = orig_text.strip()\n",
    "        row = hc_results[hc_results.test_case == orig_text]\n",
    "        toknd = row.case_templ.tolist()[0].split()\n",
    "        ## find the index of the template placeholder\n",
    "        for ii, tt in enumerate(toknd):\n",
    "            if tt[:1] == \"[\":\n",
    "                break\n",
    "        necc_vals[dataset].append(results['necc_results'][dataset][nn][ii])\n",
    "        suff_vals[dataset].append(results['suff_results'][dataset][nn][ii])\n",
    "        # necc_vals_mask[dataset].append(mask_results['necc_results_nb'][dataset][nn][ii])\n",
    "        # suff_vals_mask[dataset].append(mask_results['suff_results_nb'][dataset][nn][ii])\n",
    "\n",
    "df_dict = {('necessity', dd): ll for dd, ll in necc_vals.items()}\n",
    "df_dict.update({('sufficiency', dd): ll for dd, ll in suff_vals.items()})\n",
    "# df_dict.update({('necessity_mask', dd): ll for dd, ll in necc_vals_mask.items()})\n",
    "# df_dict.update({('sufficiency_mask', dd): ll for dd, ll in suff_vals_mask.items()})\n",
    "df_dict.update({('prediction', dd): ll for dd, ll in preds['orig_preds'].items()})\n",
    "df_dict.update({('score', dd): ll for dd, ll in preds['orig_scores'].items()})\n",
    "#df_dict.update({'target', ''}: targets)\n",
    "\n",
    "#ind = [xx.strip() for xx in perturbations['orig_texts']]\n",
    "ind = [(tt, xx.strip()) for xx, tt in zip(perturbations['orig_texts'], targets)]\n",
    "\n",
    "# pd.DataFrame(df_dict, index=ind)\n",
    "#     avg_necc[dataset] = {target: np.mean(necc_vals[target]) for target in targets}\n",
    "#     avg_suff[dataset] = {target: np.mean(suff_vals[target]) for target in targets}\n",
    "\n",
    "master_df = pd.DataFrame(df_dict, index=ind)\n",
    "master_df.columns = pd.MultiIndex.from_tuples(master_df.columns, names=['value','Dataset'])\n",
    "master_df.index = pd.MultiIndex.from_tuples(master_df.index, names=['target', 'text'])\n",
    "pickle.dump(master_df, open(\"Data/Reproduction_full/\"+model_name+\"/HateCheck_individual_necc_suff_scores.pickle\", \"wb\"))\n",
    "\n",
    "# master_df.xs('CAD_abuse', level='Dataset', axis=1)\n",
    "# master_df['necessity']\n",
    "# master_df.loc['women']\n",
    "# master_df.xs('I hate women.', level='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pickle.load(open(\"Data/Reproduction_full/\"+model_name+\"/HateCheck_individual_necc_suff_scores.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['necessity'].groupby(level='target').mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['necessity'].groupby(level='target').std().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['sufficiency'].groupby(level='target').mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['sufficiency'].groupby(level='target').std().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df['necessity_mask'].groupby(level='target').mean().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032913e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df['sufficiency_mask'].groupby(level='target').mean().transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
